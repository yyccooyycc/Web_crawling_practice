{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#射雕英雄傳一_第一回_風雲驚變.txt\n",
    "# 將每回的內文丟到append到一個json檔(for nature language practice)\n",
    "#book_toc 觀察url\n",
    "# href內../要去掉改成https://www.bookwormzz.com\n",
    "# request 可以解決\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests,urllib,re,pprint,os,json \n",
    "my_headers={\"user-agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.192 Safari/537.36\"}\n",
    "url=\"https://www.bookwormzz.com\"\n",
    "zh=\"/zh/\"\n",
    "tag1='#book_toc'\n",
    "response=requests.get(url+zh,headers=my_headers)\n",
    "soup=bs(response.text,\"lxml\")\n",
    "body=soup.select(\"a\",class_=\"epub.ui-collapsible.ui-collapsible-inset.ui-corner-all.ui-collapsible-themed-content.ui-collapsible-collapsed\")\n",
    "# print(body)\n",
    "# print(response.text)\n",
    "folderPath01=\"/Users/oliviah/Documents/Documents-2021-02-27/BDSE/Python_Scraping/scraping_HW1_novel/Novel_01\"\n",
    "if not os.path.exists(folderPath01):\n",
    "    os.makedirs(folderPath01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel=[]\n",
    "link_ch=[]\n",
    "link_ch2=[]\n",
    "link_ch3=[]\n",
    "link_ch4=[]\n",
    "title0=[]\n",
    "title=[]\n",
    "selector1=soup.select(\"a\",class_=\"ui-btn ui-btn-icon-right ui-icon-carat-r\")\n",
    "\n",
    "\n",
    "for a in selector1:\n",
    "    if a .has_attr('href'):\n",
    "        link_ch.append(a['href'].strip('..'))\n",
    "\n",
    "\n",
    "for num in range (0,len(link_ch)-1):\n",
    "        url_chapter=url+link_ch[num]+tag1\n",
    "        link_ch2.append(url_chapter)\n",
    "\n",
    "for num2 in range(0,len(link_ch2)-1):\n",
    "    response2=requests.get(link_ch2[num2],headers=my_headers)\n",
    "    soup2=bs(response2.text,\"lxml\")\n",
    "    selector2=soup2.select(\"div[data-role='content']>div>ul>li>a\")\n",
    "    selector4=soup2.select(\"head>title\")\n",
    "#     print(selector2)\n",
    "    for a in selector2:\n",
    "        if a .has_attr('href'):\n",
    "            link_ch3.append(url+a['href'])\n",
    "            title.append(a.text)\n",
    "            for b in selector4:\n",
    "                c=a.text.replace(\"\\u3000\",\"_\")\n",
    "                title0.append(b.text+\"_\"+c)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num3 in range(0,len(link_ch3)-1):\n",
    "#     print(title0[num3])\n",
    "    response3=requests.get(link_ch3[num3],headers=my_headers)\n",
    "    soup3=bs(response3.text,\"lxml\")\n",
    "    selector3=soup3.select(\"div[data-role='content'] > div \")[0].get_text()\n",
    "#寫入text\n",
    "    with open(f'{folderPath01}/{title0[num3]}.txt', 'w',encoding= 'utf-8') as file:\n",
    "        file.write(selector3)\n",
    "#寫入json\n",
    "    novel.append({num3:selector3})\n",
    "    fp = open(\"novel_all.json\", \"w\", encoding='utf-8')\n",
    "    fp.write( json.dumps(novel, ensure_ascii=False) )\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
